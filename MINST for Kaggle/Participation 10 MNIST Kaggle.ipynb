{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team name here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# MNIST Tutorial for CIS 4115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== This should generate a FutureWaring on Conversion ===== ignore this warning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print (\"====== This should generate a FutureWaring on Conversion ===== ignore this warning\")\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version  1.14.2\n",
      "Keras version  2.1.5\n"
     ]
    }
   ],
   "source": [
    "print (\"Numpy version \" , np.__version__)\n",
    "print (\"Keras version \" , keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the MNIST data\n",
    "Display some sample images and the shape of the data to make sure the import worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle uses a different set of MNIST images so don't load the built in Keras dataset\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Kaggle uses a different set of MNIST images so don't load the built in Keras dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the actual Kaggle download files instead\n",
    "# Pull out the labels or output which are saved in first index\n",
    "# Convert remaining values to floats\n",
    "train = pd.read_csv('train.csv')\n",
    "labels = train.iloc[:,0].values.astype('int32')\n",
    "X_train = (train.iloc[:,1:].values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "#reshape as 28x28 pixel images\n",
    "KX_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "KX_test = X_test.reshape(X_test.shape[0], 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is 60,000 images each 28x28 pixels greyscale:  (42000, 784)\n",
      "Testing data is 10,000 images each 28x28 pixels greyscale:  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data is 60,000 images each 28x28 pixels greyscale: \" ,X_train.shape)\n",
    "print (\"Testing data is 10,000 images each 28x28 pixels greyscale: \" ,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to display a sample of any image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2955766d780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADqRJREFUeJzt3X+s1fV9x/HXW7iiIqjUcUVEQctW1Ha0uUNbXctm6PxRg01aVrI67EivS8TIpok/sqx0sZlbVtumUg0VJqStldmqpDOrlnWRrsq8GqYIxTJ2W+8goIMM3JQf9773x/1iLnC/n3M45/s933N5Px8JOed8399zvu+c8Lrfc87n+/1+zN0FIJ6Tqm4AQDUIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoEa3cmMn2xg/RWNbuUkglHf1vzrg+62edZsKv5ldLekbkkZJetjd70utf4rG6jK7qplNAkhY72vrXrfhj/1mNkrSUknXSLpY0nwzu7jR1wPQWs18558laau7b3P3A5K+L2luMW0BKFsz4Z8s6Y0hj/uyZUcws24z6zGznoPa38TmABSpmfAP96PCMecHu/syd+9y964OjWlicwCK1Ez4+yRNGfL4PEnbm2sHQKs0E/4XJU03s2lmdrKkz0laU0xbAMrW8FCfux8ys0WSfqzBob4V7v5aYZ0BKFVT4/zu/rSkpwvqBUALcXgvEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0G1dIpu5LD0jMqjp12QrG9e3Jlb6+h8J/ncLb+7Kllv1ox/vTG3Nu0v300+t3/LtvSLD/Q30hIy7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKimxvnNrFfSPkn9kg65e1cRTZ1oTho7Nll/49bfTtb//dYHimznCP1e2ktLkjZ+bGV+8Sfp516y/JZk/YIl/5Z+AY4DSCriIJ/fc/e3CngdAC3Ex34gqGbD75KeMbOXzKy7iIYAtEazH/uvcPftZjZR0rNm9gt3f27oCtkfhW5JOkWnNbk5AEVpas/v7tuz212SnpA0a5h1lrl7l7t3dWhMM5sDUKCGw29mY81s3OH7kj4paWNRjQEoVzMf+zslPWGDp6OOlvQ9d/+nQroCULqGw+/u2ySlB6iDGHXmGcn6J9ZtT9bvmFDeOP5I9trCpcn6B/cvStanfOXnRbZzwmGoDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+4uwrn5l86WpDsm/LRFjcSy+PNPJuvfPHhDbm3y/enTgf3QoYZ6GknY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzz12n01PNza1et7mlhJ8d62/fn1q58cWHyuUsu+VFT2/7EqTuS9bNOOrWp109ZOL4vXb8t/1Tp6/75j9Mv3nPiX5eGPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBGXuJc/RPMR4m+CX2VUt216RXn/omMmI3rP1+odK3fa6d9OHY9z55Ztza2euer7odo6w7w8vT9b/9MuP59b+aNyuotup2/K95yXrDy7NvxaAJE18oD0vC77e12qv77Z61mXPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB1Tyf38xWSPqUpF3ufmm2bIKkxyRNldQraZ677ymvzfLZmDHJ+p0f/8cWdXKs1bvzjzGQyh/LTxn32AvJ+t9cOC+3duafPJJ87nWnvd1IS3WpdS0A3ZKeE+DJZz+WrPdv2Xq8LbVcPXv+RyRdfdSyuyStdffpktZmjwGMIDXD7+7PSdp91OK5klZm91dKSh8OBaDtNPqdv9Pdd0hSdjuxuJYAtELp1/Azs25J3ZJ0ik4re3MA6tTonn+nmU2SpOw29wwNd1/m7l3u3tWh9I9qAFqn0fCvkbQgu79A0lPFtAOgVWqG38welfS8pN8ysz4zWyjpPklzzOyXkuZkjwGMIJzPn+m996PJ+qYvLC1t23sH3k3Wr7n7z5P1M76THmtvV6PePy1Zv2R1b7J+X+dLBXZzfB7Ze26y/g8fyp/nQZL84IEi23kP5/MDqInwA0ERfiAowg8ERfiBoAg/EBRDfZkfb9+QrPf7QGnbvnV7+vTQ//id9FDgiWokDwVed2F66Nj350+r3gyG+gDURPiBoAg/EBThB4Ii/EBQhB8IivADQZV+GS/Utu6xjyTr56o9p4MuW//W/0zWN31marL+wk/yx/kvL/miUjbjomTdN2wqt4E6sOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY58eIdWhbb7L+Zv/4RHVvob0cbcsXUtuWpt9W6ubrwp4fCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqOc5vZiskfUrSLne/NFu2RNIXJb2ZrXaPuz9dVpNAI27/0edza9fP+1YLO2lP9ez5H5F09TDLv+buM7N/BB8YYWqG392fk7S7Bb0AaKFmvvMvMrNXzGyFmZ1VWEcAWqLR8D8o6SJJMyXtkPTVvBXNrNvMesys56DKmZ8MwPFrKPzuvtPd+919QNK3Jc1KrLvM3bvcvatDJV81EUDdGgq/mU0a8vDTkjYW0w6AVqlnqO9RSbMlnW1mfZK+JGm2mc2U5JJ6Jd1cYo8ASlAz/O4+f5jFy0voBSjUwNj+yrZ9xuvtf/xc+3cIoBSEHwiK8ANBEX4gKMIPBEX4gaC4dDdGrD0LPpqsb7j2/kS13KNNOx/Onx5cGjxApmrs+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb528DihT9M1h9/ZnayPvDKLwrspn2cdOkHkvU9f/BOsn66lTeW/8FvLUrWpxx4vrRtF4U9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/5t630mPKd79vU2nbvmn89mT93lvHJeu/+cUiuynWqBnTc2ub/+zM5HMfn7M0WZ95cnn/fWesuylZn/bX69Mv4O1wxn4ae34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCMq8xnikmU2RtErSOZIGJC1z92+Y2QRJj0maKqlX0jx335N6rfE2wS+zqwpou3ijOicm65c905db+4uzNxbdzhH2+6Fk/Zt7LsmtrXp0TtHtHOHaz6TPW79pws9zax/oKPfa+Sn378k//kCS/uW6i5P1Q796o8h2CrPe12qv77Z61q1nz39I0u3uPkPS5ZJuMbOLJd0laa27T5e0NnsMYISoGX533+HuL2f390naLGmypLmSVmarrZR0Q1lNAijecX3nN7Opkj4sab2kTnffIQ3+gZCU/twMoK3UHX4zO13SDyQtdve9x/G8bjPrMbOeg9rfSI8ASlBX+M2sQ4PB/667H77a5E4zm5TVJ0naNdxz3X2Zu3e5e1dHyZMjAqhfzfCbmUlaLmmzuw+d9nSNpAXZ/QWSniq+PQBlqWeo70pJ6yS9qsGhPkm6R4Pf+1dLOl/SryV91t13p16rnYf6avnvhfnTQa//q/Spp6hGajhvpA7l1XI8Q301T4h2959JynuxkZlkABzhB0RF+IGgCD8QFOEHgiL8QFCEHwiKS3fX6X0rXsitdZ2anq655+4Him4nhIf+54Jk/eGl1yfr5/z9htzawP+NzHH8IrHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgap7PX6SRfD5/kqVPnx59Tmeyvvmuqcn6zb+/Nlm/Y8KWZL1MH3rhxmT9nb786cXPeD297+lc1pOs+8EDyXpERV+6G8AJiPADQRF+ICjCDwRF+IGgCD8QFOEHgmKcHziBMM4PoCbCDwRF+IGgCD8QFOEHgiL8QFCEHwiqZvjNbIqZ/dTMNpvZa2Z2W7Z8iZn9l5ltyP5dW367AIpSz6QdhyTd7u4vm9k4SS+Z2bNZ7Wvu/nfltQegLDXD7+47JO3I7u8zs82SJpfdGIByHdd3fjObKunDktZnixaZ2StmtsLMzsp5TreZ9ZhZz0Htb6pZAMWpO/xmdrqkH0ha7O57JT0o6SJJMzX4yeCrwz3P3Ze5e5e7d3VoTAEtAyhCXeE3sw4NBv+77v5DSXL3ne7e7+4Dkr4taVZ5bQIoWj2/9puk5ZI2u/v9Q5ZPGrLapyVtLL49AGWp59f+KyTdKOlVMzs85/E9kuab2UxJLqlX0s2ldAigFPX82v8zScOdH/x08e0AaBWO8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTV0im6zexNSb8asuhsSW+1rIHj0669tWtfEr01qsjeLnD336hnxZaG/5iNm/W4e1dlDSS0a2/t2pdEb42qqjc+9gNBEX4gqKrDv6zi7ae0a2/t2pdEb42qpLdKv/MDqE7Ve34AFakk/GZ2tZltMbOtZnZXFT3kMbNeM3s1m3m4p+JeVpjZLjPbOGTZBDN71sx+md0OO01aRb21xczNiZmlK33v2m3G65Z/7DezUZJelzRHUp+kFyXNd/dNLW0kh5n1Supy98rHhM3s45LelrTK3S/Nlv2tpN3ufl/2h/Msd7+zTXpbIuntqmduziaUmTR0ZmlJN0i6SRW+d4m+5qmC962KPf8sSVvdfZu7H5D0fUlzK+ij7bn7c5J2H7V4rqSV2f2VGvzP03I5vbUFd9/h7i9n9/dJOjyzdKXvXaKvSlQR/smS3hjyuE/tNeW3S3rGzF4ys+6qmxlGZzZt+uHp0ydW3M/Ras7c3EpHzSzdNu9dIzNeF62K8A83+087DTlc4e4fkXSNpFuyj7eoT10zN7fKMDNLt4VGZ7wuWhXh75M0Zcjj8yRtr6CPYbn79ux2l6Qn1H6zD+88PElqdrur4n7e004zNw83s7Ta4L1rpxmvqwj/i5Kmm9k0MztZ0uckramgj2OY2djshxiZ2VhJn1T7zT68RtKC7P4CSU9V2MsR2mXm5ryZpVXxe9duM15XcpBPNpTxdUmjJK1w96+0vIlhmNmFGtzbS4OTmH6vyt7M7FFJszV41tdOSV+S9KSk1ZLOl/RrSZ9195b/8JbT22wNfnR9b+bmw9+xW9zblZLWSXpV0kC2+B4Nfr+u7L1L9DVfFbxvHOEHBMURfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvp/cCk4GAkOKWwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2955723a668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(KX_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape data\n",
    "Keras expects inputs with three values for images. Generally the x, y, and depth of the image. So a 3x4 image \n",
    "Data we are starting with with shape of (3, 4) <br>\n",
    "[ [ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;[ 9 9 9 ] ] <br>\n",
    "Data format after reshape that keras needs with with shape of (3, 4, 1) <br>\n",
    "[ [ [ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;&nbsp;[ 9 9 9 ] ] ]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training input before reshaping  (42000, 28, 28, 1)\n",
      "First image data before normalizing\n",
      "[[[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [188.]\n",
      "   [255.]\n",
      "   [ 94.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [191.]\n",
      "   [250.]\n",
      "   [253.]\n",
      "   [ 93.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [123.]\n",
      "   [248.]\n",
      "   [253.]\n",
      "   [167.]\n",
      "   [ 10.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 80.]\n",
      "   [247.]\n",
      "   [253.]\n",
      "   [208.]\n",
      "   [ 13.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 29.]\n",
      "   [207.]\n",
      "   [253.]\n",
      "   [235.]\n",
      "   [ 77.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 54.]\n",
      "   [209.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [ 88.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 93.]\n",
      "   [254.]\n",
      "   [253.]\n",
      "   [238.]\n",
      "   [170.]\n",
      "   [ 17.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 23.]\n",
      "   [210.]\n",
      "   [254.]\n",
      "   [253.]\n",
      "   [159.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 16.]\n",
      "   [209.]\n",
      "   [253.]\n",
      "   [254.]\n",
      "   [240.]\n",
      "   [ 81.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 27.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [254.]\n",
      "   [ 13.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 20.]\n",
      "   [206.]\n",
      "   [254.]\n",
      "   [254.]\n",
      "   [198.]\n",
      "   [  7.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [168.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [196.]\n",
      "   [  7.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 20.]\n",
      "   [203.]\n",
      "   [253.]\n",
      "   [248.]\n",
      "   [ 76.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 22.]\n",
      "   [188.]\n",
      "   [253.]\n",
      "   [245.]\n",
      "   [ 93.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [103.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [191.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 89.]\n",
      "   [240.]\n",
      "   [253.]\n",
      "   [195.]\n",
      "   [ 25.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 15.]\n",
      "   [220.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [ 80.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 94.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [253.]\n",
      "   [ 94.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [ 89.]\n",
      "   [251.]\n",
      "   [253.]\n",
      "   [250.]\n",
      "   [131.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [214.]\n",
      "   [218.]\n",
      "   [ 95.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "X_train = X_train.reshape(train_size, 28, 28, 1)\n",
    "X_test = X_test.reshape(test_size, 28, 28, 1)\n",
    "print (\"Shape of training input before reshaping \", X_train.shape)\n",
    "print(\"First image data before normalizing\")\n",
    "print (X_train[:1])\n",
    "#reshape for dense-only inputs\n",
    "X_train_dense = X_train.reshape(train_size, 28 * 28)\n",
    "X_test_dense = X_test.reshape(test_size, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize image data\n",
    "Greyscale pixel data is stored as integer values between 0-255.\n",
    "<br>\n",
    "Neural networks expect inputs between 0-1, so divide each pixel by 255 to normalize it. Also change the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255\n",
    "\n",
    "\n",
    "#Do the same for the dense input\n",
    "X_train_dense = X_train_dense.astype('float32')\n",
    "X_test_dense = X_test_dense.astype('float32')\n",
    "X_train_dense = X_train_dense / 255\n",
    "X_test_dense = X_test_dense / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat the output data\n",
    "\n",
    "Output data is stored in arrays named \"y\" or y_train and y_test. <br>\n",
    "Initiailly this is just the number, 0-9, that is represented by the image. <br>\n",
    "Output should be an array of 10 different values each 0 or 1. <br>\n",
    "So, convert 4 into [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 entries in output data before reformatting  [1 0 1 4 0 0 7 3 5 3]\n"
     ]
    }
   ],
   "source": [
    "print (\"First 10 entries in output data before reformatting \",labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output data after reformatting  (42000, 10)\n",
      "First 10 entries in output data after reformatting \n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(labels, 10)\n",
    "# Kaggle does not provide the testing results--we must generate and submit these\n",
    "# Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print (\"Shape of output data after reformatting \",Y_train.shape)\n",
    "print (\"First 10 entries in output data after reformatting \")\n",
    "print (Y_train[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the Neural Network\n",
    "First, define the neural network layers in the model <br>\n",
    "Second, compile the model to build it <br>\n",
    "Third, train the model using the fit command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and train simple 3-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model created\n"
     ]
    }
   ],
   "source": [
    "Simple_3layer_model = Sequential()\n",
    "Simple_3layer_model.add(Dense(32, activation='relu', input_dim=(28*28)))\n",
    "Simple_3layer_model.add(Dense(32, activation='relu'))\n",
    "Simple_3layer_model.add(Dense(10, activation='softmax'))\n",
    "print (\"Neural Network Model created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "Simple_3layer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 2s - loss: 0.4591 - acc: 0.8711\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.2092 - acc: 0.9384\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.1669 - acc: 0.9506\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.1414 - acc: 0.9586\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.1231 - acc: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2955766dbe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Fit model on training data for network with dense input layer\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "Simple_3layer_model.fit(X_train_dense, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Simple_3layer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model created\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print (\"Neural Network Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 28s - loss: 0.0373 - acc: 0.9883\n",
      "Epoch 2/20\n",
      " - 28s - loss: 0.0300 - acc: 0.9902\n",
      "Epoch 3/20\n",
      " - 28s - loss: 0.0278 - acc: 0.9906\n",
      "Epoch 4/20\n",
      " - 29s - loss: 0.0268 - acc: 0.9910\n",
      "Epoch 5/20\n",
      " - 29s - loss: 0.0217 - acc: 0.9924\n",
      "Epoch 6/20\n",
      " - 29s - loss: 0.0199 - acc: 0.9932\n",
      "Epoch 7/20\n",
      " - 30s - loss: 0.0198 - acc: 0.9930\n",
      "Epoch 8/20\n",
      " - 32s - loss: 0.0165 - acc: 0.9946\n",
      "Epoch 9/20\n",
      " - 29s - loss: 0.0146 - acc: 0.9953\n",
      "Epoch 10/20\n",
      " - 29s - loss: 0.0136 - acc: 0.9955\n",
      "Epoch 11/20\n",
      " - 28s - loss: 0.0157 - acc: 0.9946\n",
      "Epoch 12/20\n",
      " - 27s - loss: 0.0120 - acc: 0.9960\n",
      "Epoch 13/20\n",
      " - 27s - loss: 0.0131 - acc: 0.9958\n",
      "Epoch 14/20\n",
      " - 27s - loss: 0.0117 - acc: 0.9962\n",
      "Epoch 15/20\n",
      " - 27s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 16/20\n",
      " - 27s - loss: 0.0101 - acc: 0.9965\n",
      "Epoch 17/20\n",
      " - 28s - loss: 0.0102 - acc: 0.9965\n",
      "Epoch 18/20\n",
      " - 27s - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 19/20\n",
      " - 27s - loss: 0.0106 - acc: 0.9964\n",
      "Epoch 20/20\n",
      " - 28s - loss: 0.0084 - acc: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295123d1240>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model on training data for network with CNN input layer\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "#model.fit(X_train, Y_train, batch_size=32, epoch=10, verbose=1)\n",
    "model.fit(X_train_norm, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                73760     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 76,570\n",
      "Trainable params: 76,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating test predictions...\")\n",
    "preds = model.predict_classes(X_test_norm, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_preds(preds, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(fname, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_preds(preds, \"minst_kaggle_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model created\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(18, kernel_size=(2, 2), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(18, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print (\"Neural Network Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      " - 24s - loss: 0.3010 - acc: 0.9117\n",
      "Epoch 2/35\n",
      " - 24s - loss: 0.1036 - acc: 0.9686\n",
      "Epoch 3/35\n",
      " - 23s - loss: 0.0758 - acc: 0.9767\n",
      "Epoch 4/35\n",
      " - 24s - loss: 0.0626 - acc: 0.9801\n",
      "Epoch 5/35\n",
      " - 24s - loss: 0.0518 - acc: 0.9831\n",
      "Epoch 6/35\n",
      " - 23s - loss: 0.0415 - acc: 0.9871\n",
      "Epoch 7/35\n",
      " - 24s - loss: 0.0373 - acc: 0.9875\n",
      "Epoch 8/35\n",
      " - 23s - loss: 0.0299 - acc: 0.9897\n",
      "Epoch 9/35\n",
      " - 23s - loss: 0.0275 - acc: 0.9903\n",
      "Epoch 10/35\n",
      " - 23s - loss: 0.0245 - acc: 0.9918\n",
      "Epoch 11/35\n",
      " - 23s - loss: 0.0232 - acc: 0.9920\n",
      "Epoch 12/35\n",
      " - 23s - loss: 0.0210 - acc: 0.9928\n",
      "Epoch 13/35\n",
      " - 23s - loss: 0.0187 - acc: 0.9939\n",
      "Epoch 14/35\n",
      " - 23s - loss: 0.0174 - acc: 0.9941\n",
      "Epoch 15/35\n",
      " - 23s - loss: 0.0165 - acc: 0.9943\n",
      "Epoch 16/35\n",
      " - 23s - loss: 0.0160 - acc: 0.9947\n",
      "Epoch 17/35\n",
      " - 23s - loss: 0.0146 - acc: 0.9951\n",
      "Epoch 18/35\n",
      " - 23s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 19/35\n",
      " - 23s - loss: 0.0118 - acc: 0.9960\n",
      "Epoch 20/35\n",
      " - 23s - loss: 0.0116 - acc: 0.9960\n",
      "Epoch 21/35\n",
      " - 23s - loss: 0.0098 - acc: 0.9966\n",
      "Epoch 22/35\n",
      " - 23s - loss: 0.0116 - acc: 0.9960\n",
      "Epoch 23/35\n",
      " - 23s - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 24/35\n",
      " - 23s - loss: 0.0093 - acc: 0.9970\n",
      "Epoch 25/35\n",
      " - 23s - loss: 0.0105 - acc: 0.9964\n",
      "Epoch 26/35\n",
      " - 24s - loss: 0.0089 - acc: 0.9968\n",
      "Epoch 27/35\n",
      " - 23s - loss: 0.0089 - acc: 0.9970\n",
      "Epoch 28/35\n",
      " - 23s - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 29/35\n",
      " - 23s - loss: 0.0085 - acc: 0.9970\n",
      "Epoch 30/35\n",
      " - 23s - loss: 0.0081 - acc: 0.9974\n",
      "Epoch 31/35\n",
      " - 23s - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 32/35\n",
      " - 23s - loss: 0.0073 - acc: 0.9974\n",
      "Epoch 33/35\n",
      " - 23s - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 34/35\n",
      " - 23s - loss: 0.0071 - acc: 0.9976\n",
      "Epoch 35/35\n",
      " - 23s - loss: 0.0062 - acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2952fe44978>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model on training data for network with CNN input layer\n",
    "batch_size = 64\n",
    "epochs = 35\n",
    "\n",
    "#model.fit(X_train, Y_train, batch_size=32, epoch=10, verbose=1)\n",
    "model.fit(X_train_norm, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 27, 27, 18)        90        \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 18)        1314      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 18)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 13, 13, 18)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3042)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                97376     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 99,110\n",
      "Trainable params: 99,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating test predictions...\")\n",
    "preds = model.predict_classes(X_test_norm, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_preds(preds, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(fname, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_preds(preds, \"minst_kaggle_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
