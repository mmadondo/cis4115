{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run notebook on other machines at CSS\n",
    "## jupyter notebook --ip xx.xx.xx.xxx --port xxxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# MNIST Tutorial for CIS 4115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgibbons\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version  1.14.1\n",
      "Keras version  2.1.4\n"
     ]
    }
   ],
   "source": [
    "print (\"Numpy version \" , np.__version__)\n",
    "print (\"Keras version \" , keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is 60,000 images each 28x28 pixels greyscale:  (60000, 28, 28)\n",
      "Testing data is 10,000 images each 28x28 pixels greyscale:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data is 60,000 images each 28x28 pixels greyscale: \" ,X_train.shape)\n",
    "print (\"Testing data is 10,000 images each 28x28 pixels greyscale: \" ,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to display a sample of any image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e94d517080>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e950c2f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape data\n",
    "Keras expects inputs with three values for images. Generally the x, y, and depth of the image. So a 3x4 image \n",
    "Data we are starting with with shape of (3, 4) <br>\n",
    "[ [ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;[ 9 9 9 ] ] <br>\n",
    "Data format after reshape that keras needs with with shape of (3, 4, 1) <br>\n",
    "[ [ [ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;&nbsp;[ 9 9 9 ] <br>\n",
    "&nbsp;&nbsp;&nbsp;[ 9 9 9 ] ] ]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "[[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
      "    18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
      "   253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
      "   253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
      "   198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
      "    11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
      "     2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
      "    70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
      "   225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
      "   240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
      "   229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
      "   253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
      "   253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
      "    80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print (X_train.shape)\n",
    "print (X_train2.shape)\n",
    "print (X_train[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize image data\n",
    "Greyscale pixel data is stored as integer values between 0-255.\n",
    "<br>\n",
    "Neural networks expect inputs between 0-1, so divide each pixel by 255 to normalize it. Also change the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255\n",
    "X_train2 = X_train2.astype('float32')\n",
    "X_test2 = X_test2.astype('float32')\n",
    "X_train_norm2 = X_train2 / 255\n",
    "X_test_norm2 = X_test2 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.01176471]\n",
      "   [0.07058824]\n",
      "   [0.07058824]\n",
      "   [0.07058824]\n",
      "   [0.49411765]\n",
      "   [0.53333336]\n",
      "   [0.6862745 ]\n",
      "   [0.10196079]\n",
      "   [0.6509804 ]\n",
      "   [1.        ]\n",
      "   [0.96862745]\n",
      "   [0.49803922]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.11764706]\n",
      "   [0.14117648]\n",
      "   [0.36862746]\n",
      "   [0.6039216 ]\n",
      "   [0.6666667 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.88235295]\n",
      "   [0.6745098 ]\n",
      "   [0.99215686]\n",
      "   [0.9490196 ]\n",
      "   [0.7647059 ]\n",
      "   [0.2509804 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.19215687]\n",
      "   [0.93333334]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.9843137 ]\n",
      "   [0.3647059 ]\n",
      "   [0.32156864]\n",
      "   [0.32156864]\n",
      "   [0.21960784]\n",
      "   [0.15294118]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.07058824]\n",
      "   [0.85882354]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7764706 ]\n",
      "   [0.7137255 ]\n",
      "   [0.96862745]\n",
      "   [0.94509804]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3137255 ]\n",
      "   [0.6117647 ]\n",
      "   [0.41960785]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.8039216 ]\n",
      "   [0.04313726]\n",
      "   [0.        ]\n",
      "   [0.16862746]\n",
      "   [0.6039216 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.05490196]\n",
      "   [0.00392157]\n",
      "   [0.6039216 ]\n",
      "   [0.99215686]\n",
      "   [0.3529412 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.54509807]\n",
      "   [0.99215686]\n",
      "   [0.74509805]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.04313726]\n",
      "   [0.74509805]\n",
      "   [0.99215686]\n",
      "   [0.27450982]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.13725491]\n",
      "   [0.94509804]\n",
      "   [0.88235295]\n",
      "   [0.627451  ]\n",
      "   [0.42352942]\n",
      "   [0.00392157]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.31764707]\n",
      "   [0.9411765 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.46666667]\n",
      "   [0.09803922]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.1764706 ]\n",
      "   [0.7294118 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.5882353 ]\n",
      "   [0.10588235]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.0627451 ]\n",
      "   [0.3647059 ]\n",
      "   [0.9882353 ]\n",
      "   [0.99215686]\n",
      "   [0.73333335]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.9764706 ]\n",
      "   [0.99215686]\n",
      "   [0.9764706 ]\n",
      "   [0.2509804 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.18039216]\n",
      "   [0.50980395]\n",
      "   [0.7176471 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.8117647 ]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.15294118]\n",
      "   [0.5803922 ]\n",
      "   [0.8980392 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.98039216]\n",
      "   [0.7137255 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.09411765]\n",
      "   [0.44705883]\n",
      "   [0.8666667 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7882353 ]\n",
      "   [0.30588236]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.09019608]\n",
      "   [0.25882354]\n",
      "   [0.8352941 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7764706 ]\n",
      "   [0.31764707]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.07058824]\n",
      "   [0.67058825]\n",
      "   [0.85882354]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7647059 ]\n",
      "   [0.3137255 ]\n",
      "   [0.03529412]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.21568628]\n",
      "   [0.6745098 ]\n",
      "   [0.8862745 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.95686275]\n",
      "   [0.52156866]\n",
      "   [0.04313726]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.53333336]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.83137256]\n",
      "   [0.5294118 ]\n",
      "   [0.5176471 ]\n",
      "   [0.0627451 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train_norm2.shape)\n",
    "print (X_train_norm2[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reformat the output data\n",
    "\n",
    "Output data is stored in arrays named \"y\" or y_train and y_test. <br>\n",
    "Initiailly this is just the number, 0-9, that is represented by the image. <br>\n",
    "Output should be an array of 10 different values each 0 or 1. <br>\n",
    "So, convert 4 into [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print (y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print (Y_train.shape)\n",
    "print (Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgibbons\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(32,(3,3), border_mode='same',kernel_initializer='uniform',input_shape=(28,28,1),dim_ordering='tf',name='conv_1.1'))\n",
    "#model.add(Conv2D(16, 3,3, border_mode='same', input_shape=(1, 28, 28), activation='relu'))\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28,28)))\n",
    "#model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#model.add(Dense(32, activation='relu', input_dim=(28*28)))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.3272 - acc: 0.9012 - val_loss: 0.0955 - val_acc: 0.9706\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1331 - acc: 0.9605 - val_loss: 0.0655 - val_acc: 0.9780\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.1009 - acc: 0.9702 - val_loss: 0.0539 - val_acc: 0.9802\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0831 - acc: 0.9746 - val_loss: 0.0462 - val_acc: 0.9840\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.0731 - acc: 0.9774 - val_loss: 0.0439 - val_acc: 0.9856\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0642 - acc: 0.9800 - val_loss: 0.0399 - val_acc: 0.9858\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0586 - acc: 0.9815 - val_loss: 0.0368 - val_acc: 0.9865\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.0524 - acc: 0.9833 - val_loss: 0.0393 - val_acc: 0.9869\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.0485 - acc: 0.9848 - val_loss: 0.0361 - val_acc: 0.9880\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0455 - acc: 0.9855 - val_loss: 0.0335 - val_acc: 0.9887\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0405 - acc: 0.9870 - val_loss: 0.0328 - val_acc: 0.9888\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.0387 - acc: 0.9870 - val_loss: 0.0356 - val_acc: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e950c79dd8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Fit model on training data\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "#model.fit(X_train, Y_train, batch_size=32, epoch=10, verbose=1)\n",
    "#model.fit(X_train, Y_train, batch_size=32, epochs=10)\n",
    "model.fit(X_train_norm2, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_norm2, Y_test))\n",
    "# 10. Evaluate model on test data\n",
    "#score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
